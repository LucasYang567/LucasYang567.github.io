---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).

<!--
# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
-->

# üìñ Educations
- *2022.09 - 2025.06*, M.S. in the School of Automotive Studies, Tongji University, Shanghai. 
- *2018.09 - 2022.06*, B.S. in the School of Automotive Studies, Harbin Institute of Technology, Weihai.

# üíª Internships
- *2024.04 - 2025.02*,  Multi-modal Algorithm Intern, <a href='https://www.nio.cn/'>NIO</a>, Shanghai.
- *2023.07 - 2024.04*,  3D Perception Algorithm Intern, <a href='https://www.hongjingdrive.com/'>HYPERVIEW</a>, Shanghai.

<!--
# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
-->

<!--
# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.
-->

# üìù Publications 
- **<u>Lianqing Zheng*</u>**, Jianan Liu\*, Runwei Guan et al. "Doracamom: Joint 3D Detection and Occupancy Prediction with Multi-view 4D Radars and Cameras for Omnidirectional Perception," arXiv preprint arXiv:2501.15394 (2025). (submitted to *IEEE T-CSVT*) [[Paper]](https://arxiv.org/abs/2501.15394)[![](https://img.shields.io/github/stars/TJRadarLab/Doracamom?style=social&label=Code+Stars)](https://github.com/TJRadarLab/Doracamom) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:LkGwnXOMwfcC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- Long Yang\*, **<u>Lianqing Zheng*</u>**, Wenjin Ai, Minghao Liu, Sen Li et al. "MetaOcc: Surround-View 4D Radar and Camera Fusion Framework for 3D Occupancy Prediction with Dual Training Strategies," arXiv preprint arXiv:2501.15384 (2025). (submitted to *IEEE RA-L*)[[Paper]](https://arxiv.org/abs/2501.15384)[![](https://img.shields.io/github/stars/LucasYang567/MetaOcc?style=social&label=Code+Stars)](https://github.com/LucasYang567/MetaOcc) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:roLk4NBRz8UC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- **<u>Lianqing Zheng*</u>**, Long Yang\*, Qunshu Lin\*, Wenjin Ai, Minghao Liu, Shouyi Lu, Jianan Liu et al. "OmniHD-Scenes: A Next-Generation Multimodal
Dataset for Autonomous Driving," arXiv preprint arXiv:2412.10734 (2024). (submitted to *IEEE T-PAMI*)  [[Paper]](https://arxiv.org/abs/2412.10734) [[Project]](https://www.2077ai.com/OmniHD-Scenes/) [![](https://img.shields.io/github/stars/TJRadarLab/OmniHD-Scenes?style=social&label=Code+Stars)](https://github.com/TJRadarLab/OmniHD-Scenes) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:_FxGoFyzp5QC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>


